{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T15:17:27.738081Z",
     "start_time": "2018-11-08T15:17:27.086639Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../darknet\")\n",
    "\n",
    "from detector import predict\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "from postprocess import postprocess\n",
    "from args import arg_parse\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2\n",
    "from util import *\n",
    "from utils import *\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "from darknet import Darknet\n",
    "from preprocess import prep_image, inp_to_image\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle as pkl\n",
    "import itertools\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T15:17:27.744939Z",
     "start_time": "2018-11-08T15:17:27.741171Z"
    }
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.bs = 1\n",
    "        self.confidence = .5\n",
    "        self.cfgfile = \"../darknet/cfg/yolov3.cfg\"\n",
    "        self.nms_thresh = .4\n",
    "        self.weightsfile = \"../yolov3.weights\"\n",
    "        self.images = None\n",
    "        self.reso = \"416\"\n",
    "        self.scales = \"1,2,3\"\n",
    "        self.saveto = \"\"\n",
    "        self.silent = None\n",
    "        self.cuda = \"3\"\n",
    "        self.det = \"det\"\n",
    "        self.vot = \"/home/zabulskyy/data/vot2016/\"\n",
    "        self.pp = \"first_and_mfc_smart\"\n",
    "        self.saveto = \"lol.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T15:17:27.808868Z",
     "start_time": "2018-11-08T15:17:27.804373Z"
    }
   },
   "outputs": [],
   "source": [
    "crit_vals = {\n",
    "    \"iou\": 0.9999,\n",
    "    \"cc\": 0.9999,               # class_correspondence\n",
    "    \"id\": 0.9999,               # initial dist \n",
    "    \"vd\": 0.9999                # vector dist\n",
    "}\n",
    "\n",
    "cm=None\n",
    "\n",
    "args = Args()\n",
    "vot_path = args.vot\n",
    "saveto = args.saveto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T15:20:16.400399Z",
     "start_time": "2018-11-08T15:20:16.371707Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def print_tensor(tensor):\n",
    "    for row in tensor:\n",
    "        print()\n",
    "        for cell in row:\n",
    "            print(\"{0}   \".format(cell), end=\"\")\n",
    "        print()\n",
    "        \n",
    "def eval_single_class_corr(cls1 : int, cls2 : int, correlations=cm):\n",
    "    # calculate correlations between two classes\n",
    "    def read_csv(file):\n",
    "        with open(file, 'r') as file:\n",
    "            l = file.read().split(\"\\n\")\n",
    "            l.pop(-1)\n",
    "            l = [[float(x) for x in y.split(\",\")[:-1]] for y in l]   \n",
    "            return torch.tensor(l)\n",
    "    \n",
    "    if correlations is None:\n",
    "        cm = read_csv(\"correlations.csv\")\n",
    "        correlations = cm\n",
    "        \n",
    "    return float(cm[cls1][cls2])\n",
    "\n",
    "def vec_dist(vec1, vec2):\n",
    "    \n",
    "    dist = torch.nn.modules.PairwiseDistance()\n",
    "    vd = None\n",
    "    \n",
    "    if len(vec1) > 80:\n",
    "        vec1[torch.argmax(vec1[6:]) + 6] = 1\n",
    "        vec2[torch.argmax(vec2[6:]) + 6] = 1\n",
    "        vd = dist(vec1[6:].view([1, -1]), vec2[6:].view([1, -1]))\n",
    "    else:\n",
    "        vec1[torch.argmax(vec1)] = 1\n",
    "        vec2[torch.argmax(vec2)] = 1\n",
    "        vd = dist(vec1.view([1, -1]), vec2.view([1, -1])) \n",
    "    return vd\n",
    "\n",
    "def iou(boxA, boxB):\n",
    "    # IoU between two boxes\n",
    "    boxA = boxA[1:5] if len(boxA) != 4 else boxA\n",
    "    boxB = boxB[1:5] if len(boxB) != 4 else boxB\n",
    "\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    res = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return res\n",
    "\n",
    "\n",
    "def eval_energy(bb1, bb2, cv=crit_vals, ban_negative_cc=True):\n",
    "    box1, box2 = bb1[1:5], bb2[1:5]\n",
    "    cls1, cls2 = bb1[6:-2], bb2[6:-2]  # 5'th column is the precision of the bbox\n",
    "    class1, class2 = int(cls1[-1]), int(cls2[-1])\n",
    "    \n",
    "    _iou = iou(box1, box2)\n",
    "#     print(\"--------------\")\n",
    "#     print(_iou, box1, box2)\n",
    "#     print(\"--------------\")\n",
    "    _cc = eval_single_class_corr(class1, class2)\n",
    "    _vd = vec_dist(bb1, bb2)\n",
    "    \n",
    "    return {\"iou\": _iou, \"cc\": _cc, \"vd\": 1 / _vd}\n",
    "\n",
    "def cebtf(frame1, frame2, cv=crit_vals, ban_negative_cc=True):  \n",
    "    # calculate_energies_between_two_frames\n",
    "    _boxes = torch.zeros((len(frame1)))\n",
    "    _energies = torch.zeros((len(frame1)))\n",
    "    for i in range(len(frame1)):\n",
    "        max_energy = 0\n",
    "        max_energy_index = 0\n",
    "        \n",
    "        ious = torch.zeros(len(frame2))\n",
    "        ccs = torch.zeros(len(frame2))\n",
    "        vds = torch.zeros(len(frame2))\n",
    "        \n",
    "        for j in range(len(frame2)):\n",
    "            energy = eval_energy(frame1[i], frame2[j], cv, ban_negative_cc=ban_negative_cc)\n",
    "            \n",
    "            if ban_negative_cc and energy[\"cc\"] < 0:        \n",
    "                pass  # values are already 0\n",
    "            else:          \n",
    "                ious[j] = energy[\"iou\"] * cv[\"iou\"]\n",
    "                ccs[j] = energy[\"cc\"] * cv[\"cc\"]\n",
    "                vds[j] = energy[\"vd\"] * cv[\"vd\"]\n",
    "                \n",
    "        # normalize\n",
    "        ious = ious# / (torch.max(ious) + 1e-10)\n",
    "        ccs = ccs# / (torch.max(ccs) + 1e-10)\n",
    "        vds = vds / (torch.max(vds) + 1e-10)\n",
    "\n",
    "#         print(\"ious: {}, ccs: {}, vds: {}\".format(ious, ccs, vds))\n",
    "        energies = sum((ious, ccs, vds))\n",
    "#         print(\"energies:\", energies)\n",
    "        \n",
    "        _boxes[i] = torch.argmax(energies)\n",
    "        _energies[i] = torch.max(energies)\n",
    "    return _boxes, _energies\n",
    "          \n",
    "\n",
    "def select(preds, bboxes, energies, CUDA=False):\n",
    "    # do dynamic programming\n",
    "    # core function \n",
    "    \n",
    "    if CUDA:\n",
    "        dpreds, bboxes = preds.cuda(), bboxes.cuda()\n",
    "        \n",
    "    if preds.shape[0] == 0: \n",
    "        print(\"NO PREDS\")\n",
    "        return bboxes, energies\n",
    "    \n",
    "    boxes, energy = cebtf(bboxes, preds)\n",
    "    energies += energy\n",
    "    \n",
    "    return preds[boxes.long()], energies\n",
    "\n",
    "def read_gt(vot_class, vot_path, force_square=True):\n",
    "    # read the groundtruth for a precise vot class\n",
    "    gt_file = osp.join(vot_path, vot_class, \"groundtruth.txt\")\n",
    "    with open(gt_file, 'r') as file:\n",
    "        l =file.read().split(\"\\n\")\n",
    "        l.pop(-1)\n",
    "        l = [[float(x) for x in y.split(\",\")] for y in l]\n",
    "        if force_square:\n",
    "            l = [[min(m[::2]), min(m[1::2]), max(m[::2]), max(m[1::2])] for m in l]   \n",
    "        return torch.tensor(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T15:17:29.416168Z",
     "start_time": "2018-11-08T15:17:29.399088Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def predict_batch(batch, dim_list):\n",
    "    im_dim_list, inp_dim, i = dim_list\n",
    "    if CUDA:\n",
    "        batch = batch.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(Variable(batch), CUDA)\n",
    "\n",
    "    prediction = write_results(\n",
    "        prediction, confidence, num_classes, nms=True, nms_conf=nms_thesh)\n",
    "\n",
    "    if type(prediction) == int:\n",
    "        i += 1\n",
    "        return None, im_dim_list\n",
    "    \n",
    "    prediction[:, 0] += i*batch_size\n",
    "\n",
    "    for im_num, image in enumerate(imlist[i*batch_size: min((i + 1)*batch_size, len(imlist))]):\n",
    "        im_id = i*batch_size + im_num\n",
    "        objs = [classes[int(x[-1])] for x in prediction if int(x[0]) == im_id]\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "    if CUDA:\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "    im_dim_list = [x[2] for x in batches]\n",
    "    im_dim_list = torch.FloatTensor(im_dim_list).repeat(1, 2)\n",
    "\n",
    "    if CUDA:\n",
    "        im_dim_list = im_dim_list.cuda()\n",
    "\n",
    "    im_dim_list = torch.index_select(im_dim_list, 0, prediction[:, 0].long())\n",
    "    scaling_factor = torch.min(inp_dim/im_dim_list, 1)[0].view(-1, 1)\n",
    "    prediction[:, [1, 3]] -= (inp_dim - scaling_factor * im_dim_list[:, 0].view(-1, 1)) / 2\n",
    "    prediction[:, [2, 4]] -= (inp_dim - scaling_factor * im_dim_list[:, 1].view(-1, 1)) / 2\n",
    "    prediction[:, 1:5] /= scaling_factor\n",
    "\n",
    "    for j in range(prediction.shape[0]):\n",
    "        prediction[j, [1, 3]] = torch.clamp(\n",
    "            prediction[j, [1, 3]], 0.0, im_dim_list[j, 0])\n",
    "        prediction[j, [2, 4]] = torch.clamp(\n",
    "            prediction[j, [2, 4]], 0.0, im_dim_list[j, 1])\n",
    "    return prediction, im_dim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T14:31:18.078221Z",
     "start_time": "2018-11-08T14:31:15.930791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network.....\n",
      "Network successfully loaded\n",
      "\n",
      "processing ball1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ef0c6382550a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m batches = list(\n\u001b[0;32m---> 67\u001b[0;31m     map(prep_image, imlist, [inp_dim for x in range(len(imlist))]))\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0mim_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0morig_ims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/YOLO-tracker/darknet/preprocess.py\u001b[0m in \u001b[0;36mprep_image\u001b[0;34m(img, inp_dim)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \"\"\"\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0morig_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mletterbox_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "cuda_n = int(args.cuda)\n",
    "silent = args.silent == \"all\"\n",
    "if (silent):\n",
    "    import sys\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "batch_size = int(args.bs)\n",
    "confidence = float(args.confidence)\n",
    "nms_thesh = float(args.nms_thresh)\n",
    "start = 0\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.cuda\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "classes = load_classes('../data/coco.names')\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Set up the neural network\n",
    "print(\"Loading network.....\")\n",
    "model = Darknet(args.cfgfile)\n",
    "model.load_weights(args.weightsfile)\n",
    "print(\"Network successfully loaded\")\n",
    "\n",
    "model.net_info[\"height\"] = args.reso\n",
    "inp_dim = int(model.net_info[\"height\"])\n",
    "assert inp_dim % 32 == 0\n",
    "assert inp_dim > 32\n",
    "\n",
    "# If there's a GPU availible, put the model on GPU\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "print()\n",
    "# Detection phase\n",
    "\n",
    "\n",
    "folder = \"ball1\"\n",
    "\n",
    "result = dict()\n",
    "num_frames = dict()\n",
    "\n",
    "images = osp.join(vot_path, folder)\n",
    "if (not os.path.isdir(images)):\n",
    "    print(folder, \"is not a folder\")\n",
    "    exit()\n",
    "\n",
    "print(\"processing {}\".format(folder))\n",
    "\n",
    "try:\n",
    "    imlist = [osp.join(osp.realpath('.'), images, img) for img in sorted(\n",
    "        os.listdir(images))[:] if os.path.splitext(\n",
    "        img)[1] == '.png' or os.path.splitext(\n",
    "        img)[1] == '.jpeg' or os.path.splitext(img)[1] == '.jpg']\n",
    "except NotADirectoryError:\n",
    "    imlist = []\n",
    "    imlist.append(osp.join(osp.realpath('.'), images))\n",
    "except FileNotFoundError:\n",
    "    print(\"No file or directory with the name {}\".format(images))\n",
    "    exit()\n",
    "\n",
    "num_frames[folder] = len(imlist)\n",
    "\n",
    "batches = list(\n",
    "    map(prep_image, imlist, [inp_dim for x in range(len(imlist))]))\n",
    "im_batches = [x[0] for x in batches]\n",
    "orig_ims = [x[1] for x in batches]\n",
    "\n",
    "if batch_size != 1:\n",
    "    num_batches = len(imlist) // batch_size + leftover\n",
    "    im_batches = [torch.cat((\n",
    "        im_batches[i*batch_size: min((i + 1)*batch_size,\n",
    "        len(im_batches))])) for i in range(num_batches)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T11:54:25.421529Z",
     "start_time": "2018-11-07T11:53:58.553747Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k = 5  # learning delay\n",
    "s = 10  # skip every s frame\n",
    "# current_state\n",
    "\n",
    "im_dim_list = [x[2] for x in batches]\n",
    "im_dim_list = torch.FloatTensor(im_dim_list).repeat(1, 2)\n",
    "\n",
    "prev_predictions, im_dim_list = predict_batch(im_batches[0], (im_dim_list, inp_dim, 0))\n",
    "energies = torch.zeros(prev_predictions.shape[0])\n",
    "\n",
    "for i, batch in enumerate(im_batches):\n",
    "    if i == 0: continue\n",
    "    if i % s and i > k: continue\n",
    "    '''=====detection pahse====='''\n",
    "    prediction, im_dim_list = predict_batch(batch, (im_dim_list, inp_dim, i))\n",
    "    if prediction is None: continue\n",
    "    \n",
    "    '''=====selection phase=====''' \n",
    "    prediction, energies = select(prediction, prev_predictions, energies)\n",
    "    prev_predictions = prediction\n",
    "    hero = prediction[torch.argmax(energies)][1:5]\n",
    "    \n",
    "    '''=====plotting====='''\n",
    "    image = imlist[i]\n",
    "    im = Image.open(image)\n",
    "    plt.imshow(im)\n",
    "    plt.title(image.split('/')[-1])\n",
    "    if i < k:\n",
    "        for pr_bb in prediction[:, 1:5]:\n",
    "            X, Y = pr_bb[::2], pr_bb[1::2]\n",
    "            pr_bb = [min(X), min(Y), max(X),  max(Y)]\n",
    "            plt.plot([pr_bb[0], pr_bb[2], pr_bb[2], pr_bb[0], pr_bb[0], ],\n",
    "                                 [pr_bb[1], pr_bb[1], pr_bb[3], pr_bb[3], pr_bb[1], ], 'c-', lw=2)\n",
    "    else:\n",
    "        X, Y = hero[::2], hero[1::2]\n",
    "        pr_bb = [min(X), min(Y), max(X),  max(Y)]\n",
    "        plt.plot([pr_bb[0], pr_bb[2], pr_bb[2], pr_bb[0], pr_bb[0], ],\n",
    "                             [pr_bb[1], pr_bb[1], pr_bb[3], pr_bb[3], pr_bb[1], ], 'r-', lw=2)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T11:54:25.421529Z",
     "start_time": "2018-11-07T11:53:58.553747Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T14:31:23.301846Z",
     "start_time": "2018-11-08T14:31:23.293424Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(iou(torch.tensor([ 500.1022,  400.7566, 540.2401,  482.1173]), torch.tensor([491.3000, 399.0100, 540.4200, 450.7900])) > .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T15:20:19.631152Z",
     "start_time": "2018-11-08T15:20:19.625340Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vot_classes = os.listdir(vot_path)\n",
    "args = Args()\n",
    "vot_path = args.vot\n",
    "saveto = args.saveto\n",
    "batch_size = int(args.bs)\n",
    "confidence = float(args.confidence)\n",
    "nms_thesh = float(args.nms_thresh)\n",
    "start = 0\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.cuda\n",
    "CUDA = torch.cuda.is_available()\n",
    "classes = load_classes('../data/coco.names')\n",
    "num_classes = len(classes)\n",
    "\n",
    "hero_present = dict()\n",
    "hero_predicted = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T16:45:06.983294Z",
     "start_time": "2018-11-08T15:22:44.847346Z"
    }
   },
   "outputs": [],
   "source": [
    "for n, folder in enumerate(sorted(vot_classes)):\n",
    "    print(\"{} {}/{}\".format(folder, n+1, len(vot_classes)))\n",
    "    hero_present[folder] = list()\n",
    "    hero_predicted[folder] = list()\n",
    "    '''=====Load GT====='''\n",
    "    gt = read_gt(folder, vot_path)\n",
    "    \n",
    "    '''=====Set up the neural network====='''\n",
    "    model = Darknet(args.cfgfile)\n",
    "    model.load_weights(args.weightsfile)\n",
    "    model.net_info[\"height\"] = args.reso\n",
    "    inp_dim = int(model.net_info[\"height\"])\n",
    "\n",
    "    # If there's a GPU availible, put the model on GPU\n",
    "    if CUDA:\n",
    "        model.cuda()\n",
    "\n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "    # Detection phase\n",
    "\n",
    "    vot_path = args.vot\n",
    "    saveto = args.saveto\n",
    "\n",
    "    result = dict()\n",
    "    num_frames = dict()\n",
    "\n",
    "    images = osp.join(vot_path, folder)\n",
    "    if (not os.path.isdir(images)):\n",
    "        print(folder, \"is not a folder\")\n",
    "        exit()\n",
    "\n",
    "    try:\n",
    "        imlist = [osp.join(osp.realpath('.'), images, img) for img in sorted(\n",
    "            os.listdir(images))[:] if os.path.splitext(\n",
    "            img)[1] == '.png' or os.path.splitext(\n",
    "            img)[1] == '.jpeg' or os.path.splitext(img)[1] == '.jpg']\n",
    "    except NotADirectoryError:\n",
    "        imlist = []\n",
    "        imlist.append(osp.join(osp.realpath('.'), images))\n",
    "    except FileNotFoundError:\n",
    "        print(\"No file or directory with the name {}\".format(images))\n",
    "        exit()\n",
    "\n",
    "    num_frames[folder] = len(imlist)\n",
    "\n",
    "    batches = list(\n",
    "        map(prep_image, imlist, [inp_dim for x in range(len(imlist))]))\n",
    "    im_batches = [x[0] for x in batches]\n",
    "    orig_ims = [x[1] for x in batches]\n",
    "\n",
    "    if batch_size != 1:\n",
    "        num_batches = len(imlist) // batch_size + leftover\n",
    "        im_batches = [torch.cat((\n",
    "            im_batches[i*batch_size: min((i + 1)*batch_size,\n",
    "            len(im_batches))])) for i in range(num_batches)]\n",
    "\n",
    "    im_dim_list = [x[2] for x in batches]\n",
    "    im_dim_list = torch.FloatTensor(im_dim_list).repeat(1, 2)\n",
    "\n",
    "    prev_predictions, im_dim_list = predict_batch(im_batches[0], (im_dim_list, inp_dim, 0))    \n",
    "    if prev_predictions is None:\n",
    "        print(\"No object was found on the first frame in {}\".format(folder))\n",
    "        continue\n",
    "    energies = torch.zeros(prev_predictions.shape[0])\n",
    "    \n",
    "    for i, batch in enumerate(im_batches):\n",
    "        print(\"{}/{}\".format(i+1, len(im_batches)), end=\" \")\n",
    "        \n",
    "        if i == 0: continue\n",
    "        '''=====detection pahse====='''\n",
    "        predictions, im_dim_list = predict_batch(batch, (im_dim_list, inp_dim, i))\n",
    "        if predictions is None: \n",
    "            hero_predicted[folder].append(0)\n",
    "            hero_present[folder].append(0)\n",
    "            continue\n",
    "\n",
    "        '''=====selection phase=====''' \n",
    "        predictions, energies = select(predictions, prev_predictions, energies)\n",
    "        prev_predictions = predictions\n",
    "        hero = predictions[torch.argmax(energies)][1:5]\n",
    "        \n",
    "        _iou = iou(hero, gt[i])\n",
    "        if _iou > .6:\n",
    "            hero_predicted[folder].append(1)\n",
    "        else:\n",
    "            hero_predicted[folder].append(0)\n",
    "            \n",
    "        hero_present[folder].append(0)\n",
    "        for prediction in predictions:\n",
    "            _iou = iou(prediction, gt[i])\n",
    "            if _iou > .6:\n",
    "                hero_present[folder][-1] = 1\n",
    "                break       \n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T16:45:06.983294Z",
     "start_time": "2018-11-08T15:22:44.847346Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T15:17:05.533374Z",
     "start_time": "2018-11-08T15:17:05.520346Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_gt() missing 1 required positional argument: 'vot_path'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d5af0b44d701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_gt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bmx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: read_gt() missing 1 required positional argument: 'vot_path'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "gt = read_gt(\"bmx\")\n",
    "print(gt)\n",
    "for i in range(gt.shape[0]):\n",
    "    image = imlist[i]\n",
    "    im = Image.open(image)\n",
    "    plt.imshow(im)\n",
    "    plt.title(image.split('/')[-1])\n",
    "    \n",
    "    print(gt[i])\n",
    "\n",
    "    X, Y = gt[i][::2], gt[i][1::2]\n",
    "    plt.plot([gt[i][0], gt[i][2], gt[i][2], gt[i][0], gt[i][0], ],\n",
    "                         [gt[i][1], gt[i][1], gt[i][3], gt[i][3], gt[i][1], ], 'c-', lw=2)\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
